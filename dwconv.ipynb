{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "t9Nf_HKStLTX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np \n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 1000\n",
    "img_size = 128\n",
    "down_sample_img_size = 32\n",
    "train_batch_size = 16\n",
    "valid_batch_size = 1\n",
    "cover_loss_weight = 1\n",
    "secret_loss_weight = 1\n",
    "decoder_weight_loss = 1\n",
    "dataset_path = \"./new_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "yT7KkirbuDsN"
   },
   "outputs": [],
   "source": [
    "class StegDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_csv, transforms):\n",
    "        self.dataset = pd.read_csv(dataset_csv)\n",
    "        self.dataset = self.dataset.reset_index(drop=True)            \n",
    "        self.transforms = transforms\n",
    "        self.folder_type = \"training\" if \"train\" in dataset_csv else \"validation\"\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        cover_image = self.dataset.iloc[index][\"cover_image\"]\n",
    "        secret_image = self.dataset.iloc[index][\"secret_image\"]\n",
    "\n",
    "        cover_image = Image.open(os.path.join(dataset_path, self.folder_type, cover_image))\n",
    "        secret_image = Image.open(os.path.join(dataset_path, self.folder_type, secret_image))\n",
    "\n",
    "        transformed_cover_image = self.transforms(cover_image)\n",
    "        transformed_secret_image = self.transforms(secret_image)\n",
    "        \n",
    "        return {\n",
    "            \"cover_image\": transformed_cover_image,\n",
    "            \"secret_image\": transformed_secret_image\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=(3, 3), stride=stride, padding=1, groups=in_channels),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDepthwiseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_blocks, stride):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(DepthwiseSeparableConv(in_channels, out_channels, stride=stride))\n",
    "        for _ in range(num_blocks-1):\n",
    "            layers.append(DepthwiseSeparableConv(out_channels, out_channels, stride=1))\n",
    "            \n",
    "        self.sequential_layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequential_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=1, padding=1), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            MultiDepthwiseBlock(32, 32, 3, 1),\n",
    "            MultiDepthwiseBlock(32, 64, 1, 1),\n",
    "            \n",
    "            MultiDepthwiseBlock(64, 64, 3, 2),\n",
    "            MultiDepthwiseBlock(64, 128, 1, 1),\n",
    "\n",
    "            MultiDepthwiseBlock(128, 128, 3, 2),\n",
    "            MultiDepthwiseBlock(128, 256, 1, 1),\n",
    "\n",
    "            MultiDepthwiseBlock(256, 256, 3, 1),\n",
    "            MultiDepthwiseBlock(256, 150, 1, 1) \n",
    "        )\n",
    "\n",
    "    def forward(self, secret_image):\n",
    "        print(\"prep input\", secret_image.shape)\n",
    "        x = self.conv_layers(secret_image)\n",
    "        print(\"prep output\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HidingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=153, out_channels=32, kernel_size=(3, 3), stride=1, padding=1), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            MultiDepthwiseBlock(32, 32, 3, 1),\n",
    "            MultiDepthwiseBlock(32, 64, 1, 1),\n",
    "            \n",
    "            MultiDepthwiseBlock(64, 64, 3, 1),\n",
    "            MultiDepthwiseBlock(64, 128, 1, 1),\n",
    "\n",
    "            MultiDepthwiseBlock(128, 128, 3, 1),\n",
    "            MultiDepthwiseBlock(128, 256, 1, 1),\n",
    "        )\n",
    "\n",
    "        self.up_sampler = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=3, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, secret_image, cover_image):\n",
    "        print(\"secret image input\", secret_image.shape)\n",
    "        print(\"cover image before input\", cover_image.shape)\n",
    "        cover_image = F.interpolate(cover_image, size=(secret_image.shape[2], secret_image.shape[3]), mode=\"bilinear\", align_corners=False)\n",
    "        print(\"cover image input after interpolation\", cover_image.shape)\n",
    "        concatenated_image = torch.cat([secret_image, cover_image], dim=1)\n",
    "        print(\"concatenated image before conv layer\", concatenated_image.shape)\n",
    "        x = self.conv_layers(concatenated_image)\n",
    "        print(\"conv layer (hiding) input\", x.shape)\n",
    "        x = self.up_sampler(x)\n",
    "        print(\"image after up sampler\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevealNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=1, padding=1), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            MultiDepthwiseBlock(32, 32, 3, 1),\n",
    "            MultiDepthwiseBlock(32, 64, 1, 1),\n",
    "            \n",
    "            MultiDepthwiseBlock(64, 64, 3, 2),\n",
    "            MultiDepthwiseBlock(64, 128, 1, 1),\n",
    "\n",
    "            MultiDepthwiseBlock(128, 128, 3, 2),\n",
    "            MultiDepthwiseBlock(128, 256, 1, 1),\n",
    "        )\n",
    "\n",
    "        self.up_sampler = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=3, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, stego_image):\n",
    "        print(\"reveal net stego imge input\", stego_image.shape)\n",
    "        x = self.conv_layers(stego_image)\n",
    "        print(\"reveal net after conv layer\", x.shape)\n",
    "        x = self.up_sampler(x)\n",
    "        print(\"reaveal net afeter up sampler\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModel(nn.Module):\n",
    "    def __init__(self, prepNet, hidingNet):\n",
    "        super().__init__()\n",
    "        self.prepNet = prepNet\n",
    "        self.hidingNet = hidingNet\n",
    "    \n",
    "    def forward(self, cover_image, secret_image):\n",
    "        encoded_image = self.prepNet(secret_image)\n",
    "        stego_image = self.hidingNet(encoded_image, cover_image)\n",
    "        return stego_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderModel(nn.Module):\n",
    "    def __init__(self, revealNet):\n",
    "        super().__init__()\n",
    "        self.revealNet = revealNet\n",
    "    \n",
    "    def forward(self, stego_image):\n",
    "        predicted_secret_image = self.revealNet(stego_image)\n",
    "        return predicted_secret_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLoss(nn.Module):\n",
    "    def __init__(self, cover_weight, secret_weight):\n",
    "        super().__init__()\n",
    "        self.cover_weight = cover_weight\n",
    "        self.secret_weight = secret_weight\n",
    "        \n",
    "    def forward(self, cover_image, predicted_cover_image, secret_image, predicted_secret_image):\n",
    "        cover_loss = self.cover_weight * F.mse_loss(cover_image, predicted_cover_image)\n",
    "        secret_loss = self.secret_weight * F.mse_loss(secret_image, predicted_secret_image) \n",
    "        return cover_loss + secret_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLoss(nn.Module):\n",
    "    def __init__(self, decoder_loss_weight):\n",
    "        super().__init__()\n",
    "        self.decoder_loss_weight = decoder_loss_weight\n",
    "    \n",
    "    def forward(self, predicted_secret_image, secret_image):\n",
    "        reveal_img = self.decoder_loss_weight * F.mse_loss(secret_image, predicted_secret_image)\n",
    "        return reveal_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(EncoderModel(\n",
       "   (prepNet): PrepNet(\n",
       "     (conv_layers): Sequential(\n",
       "       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (4): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (5): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (6): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (7): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (8): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (9): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (10): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (hidingNet): HidingNet(\n",
       "     (conv_layers): Sequential(\n",
       "       (0): Conv2d(153, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (4): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (5): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (6): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (7): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (8): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (up_sampler): Sequential(\n",
       "       (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "       (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (5): ReLU()\n",
       "       (6): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (7): Sigmoid()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " DecoderModel(\n",
       "   (revealNet): RevealNet(\n",
       "     (conv_layers): Sequential(\n",
       "       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (4): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (5): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (6): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (7): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (8): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (up_sampler): Sequential(\n",
       "       (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "       (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (5): ReLU()\n",
       "       (6): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (7): Sigmoid()\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_net = PrepNet()\n",
    "hiding_net = HidingNet()\n",
    "reveal_net = RevealNet()\n",
    "\n",
    "encoder_model = EncoderModel(prep_net, hiding_net)\n",
    "decoder_model = DecoderModel(reveal_net)\n",
    "\n",
    "encoder_model.to(device), decoder_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_csv_path = os.path.join(dataset_path, \"train_dataset.csv\")\n",
    "validation_csv_path = os.path.join(dataset_path, \"validation_dataset.csv\")\n",
    "\n",
    "training_dataset = StegDataset(training_csv_path, transforms)\n",
    "valid_dataset = StegDataset(validation_csv_path, transforms)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(training_dataset, \n",
    "                                                batch_size=train_batch_size, \n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                num_workers=0\n",
    "                                               )\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "                                                batch_size=valid_batch_size, \n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                num_workers=0\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_loss_func = EncoderLoss(cover_loss_weight, secret_loss_weight)\n",
    "decoder_loss_func = DecoderLoss(decoder_weight_loss)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder_model.parameters(), lr=lr)\n",
    "decoder_optimizer = torch.optim.Adam(decoder_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(encoder_model,\n",
    "             decoder_model,\n",
    "             encoder_loss_func, \n",
    "             decoder_loss_func,\n",
    "             encoder_optimizer,\n",
    "             decoder_optimizer,\n",
    "             train_loader, \n",
    "             epochs,\n",
    "             print_every=50):\n",
    "    \n",
    "    encoder_loss_list = []\n",
    "    decoder_loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            cover_image = batch[\"cover_image\"].to(device)\n",
    "            secret_image = batch[\"secret_image\"].to(device)\n",
    "\n",
    "            # Phase 1: Train encoder\n",
    "            for param in encoder_model.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in decoder_model.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "            stego_image = encoder_model(cover_image, secret_image)  \n",
    "            predicted_secret_image = decoder_model(stego_image)\n",
    "            \n",
    "            encoder_loss = encoder_loss_func(cover_image, stego_image, secret_image, predicted_secret_image)\n",
    "            encoder_optimizer.zero_grad()\n",
    "            encoder_loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "\n",
    "            # Phase 2: Train Decoder\n",
    "            for param in encoder_model.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in decoder_model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            with torch.no_grad():\n",
    "                stego_image = encoder_model(cover_image, secret_image)\n",
    "\n",
    "            predicted_secret_image = decoder_model(stego_image)\n",
    "            decoder_loss = decoder_loss_func(predicted_secret_image, secret_image)\n",
    "            decoder_optimizer.zero_grad()\n",
    "            decoder_loss.backward()\n",
    "            decoder_optimizer.step()\n",
    "        \n",
    "        encoder_loss_list.append(encoder_loss.item())\n",
    "        decoder_loss_list.append(decoder_loss.item())\n",
    "        \n",
    "        # if epoch % print_every == 0:\n",
    "        print(\"encoder loss {} | decoder loss {}\".format(encoder_loss.item(), decoder_loss.item()))\n",
    "        \n",
    "    return encoder_model, decoder_model, encoder_loss_list, decoder_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "prep input torch.Size([16, 3, 128, 128])\n",
      "prep output torch.Size([16, 150, 32, 32])\n",
      "secret image input torch.Size([16, 150, 32, 32])\n",
      "cover image before input torch.Size([16, 3, 128, 128])\n",
      "cover image input after interpolation torch.Size([16, 3, 32, 32])\n",
      "concatenated image before conv layer torch.Size([16, 153, 32, 32])\n",
      "conv layer (hiding) input torch.Size([16, 256, 32, 32])\n",
      "image after up sampler torch.Size([16, 3, 128, 128])\n",
      "reveal net stego imge input torch.Size([16, 3, 128, 128])\n",
      "reveal net after conv layer torch.Size([16, 256, 32, 32])\n",
      "reaveal net afeter up sampler torch.Size([16, 3, 128, 128])\n",
      "encoder loss 0.15482541918754578 | decoder loss 0.09042655676603317\n"
     ]
    }
   ],
   "source": [
    "enc_model, dec_model, enc_loss_list, dec_loss_list = training(encoder_model, \n",
    "                                                              decoder_model,\n",
    "                                                              encoder_loss_func,\n",
    "                                                              decoder_loss_func,\n",
    "                                                              encoder_optimizer,\n",
    "                                                              decoder_optimizer,\n",
    "                                                              train_data_loader, \n",
    "                                                              1,\n",
    "                                                              50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15482541918754578]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(enc_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dec_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model.eval()\n",
    "# decoder_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data = next(iter(valid_data_loader))\n",
    "# cover_image = val_data.get(\"cover_image\")\n",
    "# secret_image = val_data.get(\"secret_image\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     stego_image = encoder_model(cover_image, secret_image)\n",
    "#     predicted_secret_image = decoder_model(stego_image)\n",
    "\n",
    "#     enc_loss = encoder_loss_func(predicted_secret_image, secret_image, stego_image, cover_image)\n",
    "#     dec_loss = decoder_loss_funct(predicted_secret_image, secret_image)\n",
    "    \n",
    "#     print(\"encoder loss => \", enc_loss)\n",
    "#     print(\"decoder loss => \", dec_loss)\n",
    "    \n",
    "#     plt.imshow(stego_image), plt.imshow(predicted_secret_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "MultiImageSteganography.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
