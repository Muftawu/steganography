{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "t9Nf_HKStLTX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np \n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 1000\n",
    "img_size = 128\n",
    "down_sample_img_size = 32\n",
    "train_batch_size = 16\n",
    "valid_batch_size = 1\n",
    "cover_loss_weight = 1\n",
    "secret_loss_weight = 1\n",
    "decoder_weight_loss = 1\n",
    "dataset_path = \"./new_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "yT7KkirbuDsN"
   },
   "outputs": [],
   "source": [
    "class StegDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_csv, transforms):\n",
    "        self.dataset = pd.read_csv(dataset_csv)\n",
    "        self.dataset = self.dataset.reset_index(drop=True)            \n",
    "        self.transforms = transforms\n",
    "        self.folder_type = \"training\" if \"train\" in dataset_csv else \"validation\"\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        cover_image = self.dataset.iloc[index][\"cover_image\"]\n",
    "        secret_image = self.dataset.iloc[index][\"secret_image\"]\n",
    "\n",
    "        cover_image = Image.open(os.path.join(dataset_path, self.folder_type, cover_image))\n",
    "        secret_image = Image.open(os.path.join(dataset_path, self.folder_type, secret_image))\n",
    "\n",
    "        transformed_cover_image = self.transforms(cover_image)\n",
    "        transformed_secret_image = self.transforms(secret_image)\n",
    "        \n",
    "        return {\n",
    "            \"cover_image\": transformed_cover_image,\n",
    "            \"secret_image\": transformed_secret_image\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=(3, 3), stride=stride, padding=1, groups=in_channels),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDepthwiseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_blocks, stride):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(DepthwiseSeparableConv(in_channels, out_channels, stride=stride))\n",
    "        for _ in range(num_blocks-1):\n",
    "            layers.append(DepthwiseSeparableConv(out_channels, out_channels, stride=stride))\n",
    "            \n",
    "        self.sequential_layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequential_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=1, padding=1), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            MultiDepthwiseBlock(32, 32, 3, 1),\n",
    "            MultiDepthwiseBlock(32, 64, 1, 1),\n",
    "            \n",
    "            MultiDepthwiseBlock(64, 64, 3, 2),\n",
    "            MultiDepthwiseBlock(64, 128, 1, 1),\n",
    "\n",
    "            MultiDepthwiseBlock(128, 128, 3, 2),\n",
    "            MultiDepthwiseBlock(128, 256, 1, 1),\n",
    "\n",
    "            MultiDepthwiseBlock(256, 256, 3, 1),\n",
    "            MultiDepthwiseBlock(256, 150, 1, 1) \n",
    "        )\n",
    "\n",
    "    def forward(self, secret_image):\n",
    "        x = self.conv_layers(secret_image)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HidingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=153, out_channels=32, kernel_size=(3, 3), stride=1, padding=1), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            MultiDepthwiseBlock(32, 32, 3, 1),\n",
    "            MultiDepthwiseBlock(32, 64, 1, 1),\n",
    "            \n",
    "            MultiDepthwiseBlock(64, 64, 3, 1),\n",
    "            MultiDepthwiseBlock(64, 128, 1, 1),\n",
    "\n",
    "            MultiDepthwiseBlock(128, 128, 3, 1),\n",
    "            MultiDepthwiseBlock(128, 256, 1, 1),\n",
    "        )\n",
    "\n",
    "        self.up_sampler = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=3, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, secret_image, cover_image):\n",
    "        print(secret_image.shape)\n",
    "        print(cover_image.shape)\n",
    "        cover_image = F.interpolate(\n",
    "            cover_image,\n",
    "            size=(secret_image.shape[2], secret_image.shape[3]),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "        concatenated_image = torch.cat([secret_image, cover_image], dim=1)\n",
    "        x = self.conv_layers(concatenated_image)\n",
    "        x = self.up_sampler(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevealNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=1, padding=1), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            MultiDepthwiseBlock(32, 32, 3, 1),\n",
    "            MultiDepthwiseBlock(32, 64, 1, 1),\n",
    "            \n",
    "            MultiDepthwiseBlock(64, 64, 3, 2),\n",
    "            MultiDepthwiseBlock(64, 128, 1, 1),\n",
    "\n",
    "            MultiDepthwiseBlock(128, 128, 3, 2),\n",
    "            MultiDepthwiseBlock(128, 256, 1, 1),\n",
    "        )\n",
    "\n",
    "        self.up_sampler = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=3, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, stego_image):\n",
    "        x = self.conv_layers(stego_image)\n",
    "        x = self.up_sampler(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModel(nn.Module):\n",
    "    def __init__(self, prepNet, hidingNet):\n",
    "        super().__init__()\n",
    "        self.prepNet = prepNet\n",
    "        self.hidingNet = hidingNet\n",
    "    \n",
    "    def forward(self, cover_image, secret_image):\n",
    "        encoded_image = self.prepNet(secret_image)\n",
    "        stego_image = self.hidingNet(encoded_image, cover_image)\n",
    "        return stego_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderModel(nn.Module):\n",
    "    def __init__(self, revealNet):\n",
    "        super().__init__()\n",
    "        self.revealNet = revealNet\n",
    "    \n",
    "    def forward(self, stego_image):\n",
    "        predicted_secret_image = self.revealNet(stego_image)\n",
    "        return predicted_secret_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLoss(nn.Module):\n",
    "    def __init__(self, cover_weight, secret_weight):\n",
    "        super().__init__()\n",
    "        self.cover_weight = cover_weight\n",
    "        self.secret_weight = secret_weight\n",
    "        \n",
    "    def forward(self, cover_image, predicted_cover_image, secret_image, predicted_secret_image):\n",
    "        cover_loss = self.cover_weight * F.mse_loss(cover_image, predicted_cover_image)\n",
    "        secret_loss = self.secret_weight * F.mse_loss(secret_image, predicted_secret_image) \n",
    "        return cover_loss + secret_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLoss(nn.Module):\n",
    "    def __init__(self, decoder_loss_weight):\n",
    "        super().__init__()\n",
    "        self.decoder_loss_weight = decoder_loss_weight\n",
    "    \n",
    "    def forward(self, predicted_secret_image, secret_image):\n",
    "        reveal_img = self.decoder_loss_weight * F.mse_loss(secret_image, predicted_secret_image)\n",
    "        return reveal_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(EncoderModel(\n",
       "   (prepNet): PrepNet(\n",
       "     (conv_layers): Sequential(\n",
       "       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (4): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (5): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (6): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (7): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (8): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (9): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (10): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (hidingNet): HidingNet(\n",
       "     (conv_layers): Sequential(\n",
       "       (0): Conv2d(153, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (4): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (5): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (6): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (7): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (8): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (up_sampler): Sequential(\n",
       "       (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "       (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (5): ReLU()\n",
       "       (6): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (7): Sigmoid()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " DecoderModel(\n",
       "   (revealNet): RevealNet(\n",
       "     (conv_layers): Sequential(\n",
       "       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (4): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "               (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (5): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (6): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "               (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (7): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (1): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "           (2): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (8): MultiDepthwiseBlock(\n",
       "         (sequential_layers): Sequential(\n",
       "           (0): DepthwiseSeparableConv(\n",
       "             (depthwise): Sequential(\n",
       "               (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "             (pointwise): Sequential(\n",
       "               (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               (2): ReLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (up_sampler): Sequential(\n",
       "       (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "       (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (5): ReLU()\n",
       "       (6): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (7): Sigmoid()\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_net = PrepNet()\n",
    "hiding_net = HidingNet()\n",
    "reveal_net = RevealNet()\n",
    "\n",
    "encoder_model = EncoderModel(prep_net, hiding_net)\n",
    "decoder_model = DecoderModel(reveal_net)\n",
    "\n",
    "encoder_model.to(device), decoder_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_csv_path = os.path.join(dataset_path, \"train_dataset.csv\")\n",
    "validation_csv_path = os.path.join(dataset_path, \"validation_dataset.csv\")\n",
    "\n",
    "training_dataset = StegDataset(training_csv_path, transforms)\n",
    "valid_dataset = StegDataset(validation_csv_path, transforms)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(training_dataset, \n",
    "                                                batch_size=train_batch_size, \n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                num_workers=0\n",
    "                                               )\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "                                                batch_size=valid_batch_size, \n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                num_workers=0\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_loss_func = EncoderLoss(cover_loss_weight, secret_loss_weight)\n",
    "decoder_loss_func = DecoderLoss(decoder_weight_loss)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder_model.parameters(), lr=lr)\n",
    "decoder_optimizer = torch.optim.Adam(decoder_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(encoder_model,\n",
    "             decoder_model,\n",
    "             encoder_loss_func, \n",
    "             decoder_loss_func,\n",
    "             encoder_optimizer,\n",
    "             decoder_optimizer,\n",
    "             train_loader, \n",
    "             epochs,\n",
    "             print_every=50):\n",
    "    \n",
    "    encoder_loss_list = []\n",
    "    decoder_loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            cover_image = batch[\"cover_image\"].to(device)\n",
    "            secret_image = batch[\"secret_image\"].to(device)\n",
    "\n",
    "            # Phase 1: Train encoder\n",
    "            for param in encoder_model.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in decoder_model.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "            stego_image = encoder_model(cover_image, secret_image)  \n",
    "            predicted_secret_image = decoder_model(stego_image)\n",
    "            \n",
    "            encoder_loss = encoder_loss_func(cover_image, stego_image, secret_image, predicted_secret_image)\n",
    "            encoder_optimizer.zero_grad()\n",
    "            encoder_loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "\n",
    "            # Phase 2: Train Decoder\n",
    "            for param in encoder_model.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in decoder_model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            with torch.no_grad():\n",
    "                stego_image = encoder_model(cover_image, secret_image)\n",
    "\n",
    "            predicted_secret_image = decoder_model(stego_image)\n",
    "            decoder_loss = decoder_loss_func(predicted_secret_image, secret_image)\n",
    "            decoder_optimizer.zero_grad()\n",
    "            decoder_loss.backward()\n",
    "            decoder_optimizer.step()\n",
    "        \n",
    "        encoder_loss_list.append(encoder_loss.item())\n",
    "        decoder_loss_list.append(decoder_loss.item())\n",
    "        \n",
    "        # if epoch % print_every == 0:\n",
    "        print(\"encoder loss {} | decoder loss {}\".format(encoder_loss.item(), decoder_loss.item()))\n",
    "        \n",
    "    return encoder_model, decoder_model, encoder_loss_list, decoder_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 150, 2, 2])\n",
      "torch.Size([16, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29234/1950762042.py:8: UserWarning: Using a target size (torch.Size([16, 3, 8, 8])) that is different to the input size (torch.Size([16, 3, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  cover_loss = self.cover_weight * F.mse_loss(cover_image, predicted_cover_image)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (8) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m enc_model, dec_model, enc_loss_list, dec_loss_list \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mdecoder_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mencoder_loss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mdecoder_loss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[97], line 28\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(encoder_model, decoder_model, encoder_loss_func, decoder_loss_func, encoder_optimizer, decoder_optimizer, train_loader, epochs, print_every)\u001b[0m\n\u001b[1;32m     25\u001b[0m stego_image \u001b[38;5;241m=\u001b[39m encoder_model(cover_image, secret_image)  \n\u001b[1;32m     26\u001b[0m predicted_secret_image \u001b[38;5;241m=\u001b[39m decoder_model(stego_image)\n\u001b[0;32m---> 28\u001b[0m encoder_loss \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_loss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcover_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstego_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecret_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_secret_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m encoder_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m encoder_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/venvs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[92], line 8\u001b[0m, in \u001b[0;36mEncoderLoss.forward\u001b[0;34m(self, cover_image, predicted_cover_image, secret_image, predicted_secret_image)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, cover_image, predicted_cover_image, secret_image, predicted_secret_image):\n\u001b[0;32m----> 8\u001b[0m     cover_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcover_weight \u001b[38;5;241m*\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcover_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_cover_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     secret_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msecret_weight \u001b[38;5;241m*\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(secret_image, predicted_secret_image) \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cover_loss \u001b[38;5;241m+\u001b[39m secret_loss\n",
      "File \u001b[0;32m~/venvs/ml/lib/python3.12/site-packages/torch/nn/functional.py:3884\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction, weight)\u001b[0m\n\u001b[1;32m   3881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3882\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3884\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3887\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n",
      "File \u001b[0;32m~/venvs/ml/lib/python3.12/site-packages/torch/functional.py:77\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (8) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "enc_model, dec_model, enc_loss_list, dec_loss_list = training(encoder_model, \n",
    "                                                              decoder_model,\n",
    "                                                              encoder_loss_func,\n",
    "                                                              decoder_loss_func,\n",
    "                                                              encoder_optimizer,\n",
    "                                                              decoder_optimizer,\n",
    "                                                              train_data_loader, \n",
    "                                                              1,\n",
    "                                                              50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(enc_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(dec_loss_list)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model.eval()\n",
    "# decoder_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data = next(iter(valid_data_loader))\n",
    "# cover_image = val_data.get(\"cover_image\")\n",
    "# secret_image = val_data.get(\"secret_image\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     stego_image = encoder_model(cover_image, secret_image)\n",
    "#     predicted_secret_image = decoder_model(stego_image)\n",
    "\n",
    "#     enc_loss = encoder_loss_func(predicted_secret_image, secret_image, stego_image, cover_image)\n",
    "#     dec_loss = decoder_loss_funct(predicted_secret_image, secret_image)\n",
    "    \n",
    "#     print(\"encoder loss => \", enc_loss)\n",
    "#     print(\"decoder loss => \", dec_loss)\n",
    "    \n",
    "#     plt.imshow(stego_image), plt.imshow(predicted_secret_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "MultiImageSteganography.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
