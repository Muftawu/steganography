{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t9Nf_HKStLTX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6aSpU-eEtSoJ"
   },
   "outputs": [],
   "source": [
    "dataset_path = \"../scripts/new_data\"\n",
    "train_csv = \"train_dataset.csv\"\n",
    "valid_csv = \"validation_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "LEARNING_RATE  = 0.001\n",
    "COVER_LOSS_WEIGHT = 1\n",
    "SECRET_LOSS_WEIGHT = 1\n",
    "DECODER_LOSS_WEIGHT = 1\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 1\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "yT7KkirbuDsN"
   },
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    'train_transforms':torchvision.transforms.Compose([torchvision.transforms.Resize((IMG_SIZE, IMG_SIZE)), torchvision.transforms.ToTensor()]),\n",
    "}\n",
    "\n",
    "class StegDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_csv, transforms):\n",
    "        self.dataset = pd.read_csv(dataset_csv)\n",
    "        self.dataset = self.dataset.reset_index(drop=True)            \n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        cover_image = self.dataset.iloc[index][\"cover_image\"]\n",
    "        secret_image = self.dataset.iloc[index][\"secret_image\"]\n",
    "        \n",
    "        cover_image = Image.open(os.path.join(dataset_path, \"training\", cover_image))\n",
    "        secret_image = Image.open(os.path.join(dataset_path, \"validation\", secret_image))\n",
    "        \n",
    "        transformed_cover_image = self.transforms(cover_image)\n",
    "        transformed_secret_image = self.transforms(secret_image)\n",
    "        \n",
    "        return {\n",
    "            \"cover_image\": transformed_cover_image,\n",
    "            \"secret_image\": transformed_secret_image\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()   \n",
    "        # first inception block\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,  out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "        # second inception block\n",
    "        self.conv6 = nn.Conv2d(in_channels=3,   out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv7 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv8 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv9 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv10 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "\n",
    "        # third inception block\n",
    "        self.conv11 = nn.Conv2d(in_channels=3,  out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv12 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv13 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv14 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv15 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "    \n",
    "    def forward(self, secret_image):\n",
    "        # first inception block (3x3)\n",
    "        x1 = F.relu(self.conv1(secret_image))\n",
    "        x1 = F.relu(self.conv2(x1))\n",
    "        x1 = F.relu(self.conv3(x1))\n",
    "        x1 = F.relu(self.conv4(x1))\n",
    "        x1 = F.relu(self.conv5(x1))\n",
    "\n",
    "        # second inception block (4x4)\n",
    "        x2 = F.relu(self.conv6(secret_image))\n",
    "        x2 = F.relu(self.conv7(x2))\n",
    "        x2 = F.relu(self.conv8(x2))\n",
    "        x2 = F.relu(self.conv9(x2))\n",
    "        x2 = F.relu(self.conv10(x2))\n",
    "\n",
    "        #  third inception block (5x5)\n",
    "        x3 = F.relu(self.conv11(secret_image))\n",
    "        x3 = F.relu(self.conv12(x3))\n",
    "        x3 = F.relu(self.conv13(x3))\n",
    "        x3 = F.relu(self.conv14(x3))\n",
    "        x3 = F.relu(self.conv15(x3))\n",
    "        \n",
    "        final_concat_image = torch.cat([x1, x2, x3], dim=1)\n",
    "        return final_concat_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HidingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "       # first inception block\n",
    "        self.conv1 = nn.Conv2d(in_channels=153, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "        # second inception block\n",
    "        self.conv6 = nn.Conv2d(in_channels=153, out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv7 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv8 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv9 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv10 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "\n",
    "        # third inception block\n",
    "        self.conv11 = nn.Conv2d(in_channels=153, out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv12 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv13 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv14 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv15 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(in_channels=150, out_channels=3, kernel_size=(3,3), stride=1, padding=1)\n",
    "                \n",
    "    def forward(self, secret_image, cover_image):\n",
    "        concatenated_secrets = torch.cat([cover_image, secret_image], dim=1)\n",
    "\n",
    "        # first inception block (3x3)\n",
    "        x1 = F.relu(self.conv1(concatenated_secrets))\n",
    "        x1 = F.relu(self.conv2(x1))\n",
    "        x1 = F.relu(self.conv3(x1))\n",
    "        x1 = F.relu(self.conv4(x1))\n",
    "        x1 = F.relu(self.conv5(x1))\n",
    "\n",
    "        # second inception block (4x4)\n",
    "        x2 = F.relu(self.conv6(concatenated_secrets))\n",
    "        x2 = F.relu(self.conv7(x2))\n",
    "        x2 = F.relu(self.conv8(x2))\n",
    "        x2 = F.relu(self.conv9(x2))\n",
    "        x2 = F.relu(self.conv10(x2))\n",
    "\n",
    "        #  third inception block (5x5)\n",
    "        x3 = F.relu(self.conv11(concatenated_secrets))\n",
    "        x3 = F.relu(self.conv12(x3))\n",
    "        x3 = F.relu(self.conv13(x3))\n",
    "        x3 = F.relu(self.conv14(x3))\n",
    "        x3 = F.relu(self.conv15(x3))\n",
    "\n",
    "        # stego image \n",
    "        stego_image = F.relu(self.final_layer(torch.cat([x1, x2, x3], dim=1)))\n",
    "        return stego_image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevealNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "         # first inception block\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,  out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "        # second inception block\n",
    "        self.conv6 = nn.Conv2d(in_channels=3,   out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv7 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv8 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv9 = nn.Conv2d(in_channels=50,  out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "        self.conv10 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(4, 4), stride=1, padding=\"same\")\n",
    "\n",
    "        # third inception block\n",
    "        self.conv11 = nn.Conv2d(in_channels=3,  out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv12 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv13 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv14 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        self.conv15 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=(5, 5), stride=1, padding=2)\n",
    "        \n",
    "        self.final_layer = nn.Conv2d(in_channels=150, out_channels=3, kernel_size=(3,3), stride=1, padding=1)    \n",
    "    \n",
    "    def forward(self, stego_image):\n",
    "        # first inception block (3x3)\n",
    "        x1 = F.relu(self.conv1(stego_image))\n",
    "        x1 = F.relu(self.conv2(x1))\n",
    "        x1 = F.relu(self.conv3(x1))\n",
    "        x1 = F.relu(self.conv4(x1))\n",
    "        x1 = F.relu(self.conv5(x1))\n",
    "\n",
    "        # second inception block (4x4)\n",
    "        x2 = F.relu(self.conv6(stego_image))\n",
    "        x2 = F.relu(self.conv7(x2))\n",
    "        x2 = F.relu(self.conv8(x2))\n",
    "        x2 = F.relu(self.conv9(x2))\n",
    "        x2 = F.relu(self.conv10(x2))\n",
    "\n",
    "        #  third inception block (5x5)\n",
    "        x3 = F.relu(self.conv11(stego_image))\n",
    "        x3 = F.relu(self.conv12(x3))\n",
    "        x3 = F.relu(self.conv13(x3))\n",
    "        x3 = F.relu(self.conv14(x3))\n",
    "        x3 = F.relu(self.conv15(x3))\n",
    "\n",
    "        recovered_img = F.relu(self.final_layer(torch.cat([x1, x2, x3], dim=1)))        \n",
    "        return recovered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModel(nn.Module):\n",
    "    def __init__(self, prepNet, hidingNet):\n",
    "        super().__init__()\n",
    "        self.prepNet = prepNet\n",
    "        self.hidingNet = hidingNet\n",
    "    \n",
    "    def forward(self, cover_image, secret_image):\n",
    "        encoded_image = self.prepNet(secret_image)\n",
    "        stego_image = self.hidingNet(encoded_image, cover_image)\n",
    "        return stego_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderModel(nn.Module):\n",
    "    def __init__(self, revealNet):\n",
    "        super().__init__()\n",
    "        self.revealNet = revealNet\n",
    "    \n",
    "    def forward(self, stego_image, secret_image):\n",
    "        predicted_secret_image = self.revealNet(stego_image)\n",
    "        return predicted_secret_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLoss(nn.Module):\n",
    "    def __init__(self, cover_weight, secret_weight):\n",
    "        super().__init__()\n",
    "        self.cover_weight = cover_weight\n",
    "        self.secret_weight = secret_weight\n",
    "        \n",
    "    def forward(self, predicted_secret_image, secret_image, predicted_cover_image, cover_image):\n",
    "        cover_loss = self.cover_weight * F.mse_loss(predicted_cover_image, cover_image)\n",
    "        secret_loss = self.secret_weight * F.mse_loss(predicted_secret_image, secret_image) \n",
    "        return cover_loss + secret_loss\n",
    "\n",
    "class DecoderLoss(nn.Module):\n",
    "    def __init__(self, decoder_loss_weight):\n",
    "        super().__init__()\n",
    "        self.decoder_loss_weight = decoder_loss_weight\n",
    "    \n",
    "    def forward(self, predicted_secret_image, secret_image):\n",
    "        reveal_img = self.decoder_loss_weight * F.mse_loss(predicted_secret_image, secret_image)\n",
    "        return reveal_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(EncoderModel(\n",
       "   (prepNet): PrepNet(\n",
       "     (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv3): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv4): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv5): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv6): Conv2d(3, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv7): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv8): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv9): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv10): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv11): Conv2d(3, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv12): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv13): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv14): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv15): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   )\n",
       "   (hidingNet): HidingNet(\n",
       "     (conv1): Conv2d(153, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv3): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv4): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv5): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv6): Conv2d(153, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv7): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv8): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv9): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv10): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv11): Conv2d(153, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv12): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv13): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv14): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv15): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (final_layer): Conv2d(150, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   )\n",
       " ),\n",
       " DecoderModel(\n",
       "   (revealNet): RevealNet(\n",
       "     (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv3): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv4): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv5): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv6): Conv2d(3, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv7): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv8): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv9): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv10): Conv2d(50, 50, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "     (conv11): Conv2d(3, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv12): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv13): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv14): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (conv15): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (final_layer): Conv2d(150, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_net = PrepNet()\n",
    "hiding_net = HidingNet()\n",
    "reveal_net = RevealNet()\n",
    "\n",
    "encoder_model = EncoderModel(prep_net, hiding_net)\n",
    "decoder_model = DecoderModel(reveal_net)\n",
    "\n",
    "encoder_model.to(device), decoder_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_csv_path = os.path.join(dataset_path, \"train_dataset.csv\")\n",
    "validation_csv_path = os.path.join(dataset_path, \"validation_dataset.csv\")\n",
    "\n",
    "training_dataset = StegDataset(training_csv_path, transformations[\"train_transforms\"])\n",
    "valid_dataset = StegDataset(validation_csv_path, transformations[\"train_transforms\"])\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(training_dataset, \n",
    "                                                batch_size=TRAIN_BATCH_SIZE, \n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                num_workers=0\n",
    "                                               )\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "                                                batch_size=VALID_BATCH_SIZE, \n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                num_workers=0\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_loss_func = EncoderLoss(SECRET_LOSS_WEIGHT, COVER_LOSS_WEIGHT)\n",
    "decoder_loss_func = DecoderLoss(DECODER_LOSS_WEIGHT)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder_model.parameters(), lr=LEARNING_RATE)\n",
    "decoder_optimizer = torch.optim.Adam(decoder_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(encoder_model,\n",
    "             decoder_model,\n",
    "             encoder_loss_func, \n",
    "             decoder_loss_func,\n",
    "             encoder_optimizer,\n",
    "             decoder_optimizer,\n",
    "             train_loader, \n",
    "             epochs,\n",
    "             print_every=50):\n",
    "    \n",
    "    encoder_loss_list = []\n",
    "    decoder_loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            cover_image = batch[\"cover_image\"].to(device)\n",
    "            secret_image = batch[\"secret_image\"].to(device)\n",
    "\n",
    "            # Phase 1: Train encoder\n",
    "            for param in encoder_model.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in decoder_model.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "            stego_image = encoder_model(cover_image, secret_image)  \n",
    "            predicted_secret_image = decoder_model(stego_image)\n",
    "            encoder_loss = encoder_loss_func(predicted_secret_image, secret_image, stego_image, cover_image)\n",
    "            encoder_optimizer.zero_grad()\n",
    "            encoder_loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "\n",
    "            # Phase 2: Train Decoder\n",
    "            for param in encoder_model.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in decoder_model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            with torch.no_grad():\n",
    "                stego_image = encoder_model(cover_image, secret_image)\n",
    "\n",
    "            predicted_secret_image = decoder_model(stego_image)\n",
    "            decoder_loss = decoder_loss_func(predicted_secret_image, secret_image)\n",
    "            decoder_optimizer.zero_grad()\n",
    "            decoder_loss.backwards()\n",
    "            decoder_optimizer.step()\n",
    "        \n",
    "        encoder_loss_list.append(encoder_loss.item())\n",
    "        decoder_loss_list.append(decoder_loss.item())\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            print(\"encoder loss {} | decoder loss {}\".format(encoder_loss.item(), decoder_loss.item()))\n",
    "        \n",
    "    return encoder_model, decoder_model, encoder_loss_list, decoder_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_model, dec_model, enc_loss_list, dec_loss_list = training(encoder_model, \n",
    "#                                                               decoder_model,\n",
    "#                                                               encoder_loss_func,\n",
    "#                                                               decoder_loss_func,\n",
    "#                                                               encoder_optimizer,\n",
    "#                                                               decoder_optimizer,\n",
    "#                                                               train_data_loader, \n",
    "#                                                               EPOCHS,\n",
    "#                                                               50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(enc_loss_list)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(dec_loss_list)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model.eval()\n",
    "# decoder_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data = next(iter(valid_data_loader))\n",
    "# cover_image = val_data.get(\"cover_image\")\n",
    "# secret_image = val_data.get(\"secret_image\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     stego_image = encoder_model(cover_image, secret_image)\n",
    "#     predicted_secret_image = decoder_model(stego_image)\n",
    "\n",
    "#     enc_loss = encoder_loss_func(predicted_secret_image, secret_image, stego_image, cover_image)\n",
    "#     dec_loss = decoder_loss_funct(predicted_secret_image, secret_image)\n",
    "    \n",
    "#     print(\"encoder loss => \", enc_loss)\n",
    "#     print(\"decoder loss => \", dec_loss)\n",
    "    \n",
    "#     plt.imshow(stego_image), plt.imshow(predicted_secret_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "MultiImageSteganography.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
